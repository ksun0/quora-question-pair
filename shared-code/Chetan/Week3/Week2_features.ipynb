{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df100 = df.head(1000)\n",
    "df1 = df.copy()\n",
    "df2 = df.copy()\n",
    "df3 = df.copy()\n",
    "df4 = df3.head(10000)\n",
    "df1.shape\n",
    "df3True = df3.loc[df3['target'] == 1]\n",
    "df3False = df3.loc[df3['target'] != 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Uppercase</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>No_of_QuestionMarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  word_count  Uppercase  Lowercase  No_of_QuestionMarks  \n",
       "0       0          13          2         53                    1  \n",
       "1       0          16          1         63                    1  \n",
       "2       0          10          2         54                    2  \n",
       "3       0           9          4         44                    1  \n",
       "4       0          15          3         59                    1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1['word_count'] = df1['question_text'].str.split().str.len()                # Number of words per questions\n",
    "df1['Uppercase'] = df1['question_text'].str.findall(r'[A-Z]').str.len()       # Number of upper case letters\n",
    "df1['Lowercase'] = df1['question_text'].str.findall(r'[a-z]').str.len()       # Number of lowercase letters\n",
    "df1['No_of_QuestionMarks'] = df1['question_text'].str.findall(r'\\?').str.len()# Number of question Marks\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Uppercase</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>No_of_QuestionMarks</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stop_words_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>[did, their, as, a, in, the]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, have, an, how, you, to, and, not]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>[does]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>[did, the]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>[to, a, by, just, the]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  word_count  Uppercase  Lowercase  No_of_QuestionMarks  \\\n",
       "0       0          13          2         53                    1   \n",
       "1       0          16          1         63                    1   \n",
       "2       0          10          2         54                    2   \n",
       "3       0           9          4         44                    1   \n",
       "4       0          15          3         59                    1   \n",
       "\n",
       "                                stop_words  stop_words_len  \n",
       "0             [did, their, as, a, in, the]               6  \n",
       "1  [you, have, an, how, you, to, and, not]               8  \n",
       "2                                   [does]               1  \n",
       "3                               [did, the]               2  \n",
       "4                   [to, a, by, just, the]               5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## extract stop words and count them\n",
    "df1['stop_words'] = df1['question_text'].apply(lambda x: [item for item in x.split() if item in stop])\n",
    "df1['stop_words_len'] = df1['stop_words'].str.len()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode question types as a one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstWordTrue = df3True['question_text'].str.split().str[0]\n",
    "firstWordFalse = df3False['question_text'].str.split().str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueCount = firstWordTrue.value_counts().index.tolist()[:20]\n",
    "FalseCount = firstWordFalse.value_counts().index.tolist()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countStartWord_anywhereT(x):\n",
    "    zeros = np.zeros(len(TrueCount))\n",
    "    for item in x.split():\n",
    "        if item in TrueCount:\n",
    "            zeros[TrueCount.index(item)] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def countStartWord_onlyBeginingT(x):\n",
    "    zeros = np.zeros(len(TrueCount))\n",
    "    if x.split()[0] in TrueCount:\n",
    "        zeros[TrueCount.index(x.split()[0])] = 1\n",
    "        return zeros\n",
    "    return zeros\n",
    "\n",
    "def countStartWordOccurenceT(x):\n",
    "    count = 0\n",
    "    for item in x.split():\n",
    "        if item in TrueCount:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "def countStartWord_anywhereF(x):\n",
    "    zeros = np.zeros(len(FalseCount))\n",
    "    for item in x.split():\n",
    "        if item in FalseCount:\n",
    "            zeros[FalseCount.index(item)] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def countStartWord_onlyBeginingF(x):\n",
    "    zeros = np.zeros(len(FalseCount))\n",
    "    if x.split()[0] in FalseCount:\n",
    "        zeros[FalseCount.index(x.split()[0])] = 1\n",
    "        return zeros\n",
    "    return zeros\n",
    "\n",
    "def countStartWordOccurenceF(x):\n",
    "    count = 0\n",
    "    for item in x.split():\n",
    "        if item in FalseCount:\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['countStartWord_anywhere_inText'] = -1\n",
    "df1['countStartWord_anywhere_inText'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWord_anywhereT)\n",
    "df1['countStartWord_anywhere_inText'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWord_anywhereF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['countStartWord_Occurence'] = -1\n",
    "df1['countStartWord_Occurence'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWordOccurenceT)\n",
    "df1['countStartWord_Occurence'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWordOccurenceF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['countStartWord_onlyAtStart_inText'] = -1\n",
    "df1['countStartWord_onlyAtStart_inText'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWord_onlyBeginingT)\n",
    "df1['countStartWord_onlyAtStart_inText'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWord_onlyBeginingF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Uppercase</th>\n",
       "      <th>Lowercase</th>\n",
       "      <th>No_of_QuestionMarks</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>countStartWord_anywhere_inText</th>\n",
       "      <th>countStartWord_Occurence</th>\n",
       "      <th>countStartWord_onlyAtStart_inText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>[did, their, as, a, in, the]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, have, an, how, you, to, and, not]</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>[does]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>[did, the]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>[to, a, by, just, the]</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  word_count  Uppercase  Lowercase  No_of_QuestionMarks  \\\n",
       "0       0          13          2         53                    1   \n",
       "1       0          16          1         63                    1   \n",
       "2       0          10          2         54                    2   \n",
       "3       0           9          4         44                    1   \n",
       "4       0          15          3         59                    1   \n",
       "\n",
       "                                stop_words  stop_words_len  \\\n",
       "0             [did, their, as, a, in, the]               6   \n",
       "1  [you, have, an, how, you, to, and, not]               8   \n",
       "2                                   [does]               1   \n",
       "3                               [did, the]               2   \n",
       "4                   [to, a, by, just, the]               5   \n",
       "\n",
       "                      countStartWord_anywhere_inText  \\\n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "   countStartWord_Occurence                  countStartWord_onlyAtStart_inText  \n",
       "0                         1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1                         1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "2                         2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3                         1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4                         2  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode question N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondWordTrue2 = df3True['question_text'].str.split().str[1]\n",
    "secondWordFalse2 = df3False['question_text'].str.split().str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueCount2 = secondWordTrue2 .value_counts().index.tolist()[:20]\n",
    "FalseCount2 = secondWordFalse2.value_counts().index.tolist()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "TrueCountNGram = []\n",
    "for x in itertools.product(TrueCount,TrueCount2):\n",
    "    k = ' '.join(x)\n",
    "    TrueCountNGram.append(k)\n",
    "\n",
    "import itertools\n",
    "FalseCountNGram = []\n",
    "for x in itertools.product(FalseCount,FalseCount2):\n",
    "    k = ' '.join(x)\n",
    "    TrueCountNGram.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why do',\n",
       " 'Why are',\n",
       " 'Why is',\n",
       " 'Why the',\n",
       " 'Why it',\n",
       " 'Why does',\n",
       " 'Why you',\n",
       " 'Why can',\n",
       " 'Why did',\n",
       " 'Why a',\n",
       " \"Why don't\",\n",
       " 'Why I',\n",
       " 'Why will',\n",
       " 'Why there',\n",
       " 'Why would',\n",
       " 'Why many',\n",
       " 'Why Trump',\n",
       " 'Why we',\n",
       " 'Why Indian',\n",
       " \"Why can't\",\n",
       " 'Is do',\n",
       " 'Is are',\n",
       " 'Is is',\n",
       " 'Is the',\n",
       " 'Is it',\n",
       " 'Is does',\n",
       " 'Is you',\n",
       " 'Is can',\n",
       " 'Is did',\n",
       " 'Is a',\n",
       " \"Is don't\",\n",
       " 'Is I',\n",
       " 'Is will',\n",
       " 'Is there',\n",
       " 'Is would',\n",
       " 'Is many',\n",
       " 'Is Trump',\n",
       " 'Is we',\n",
       " 'Is Indian',\n",
       " \"Is can't\",\n",
       " 'How do',\n",
       " 'How are',\n",
       " 'How is',\n",
       " 'How the',\n",
       " 'How it',\n",
       " 'How does',\n",
       " 'How you',\n",
       " 'How can',\n",
       " 'How did',\n",
       " 'How a',\n",
       " \"How don't\",\n",
       " 'How I',\n",
       " 'How will',\n",
       " 'How there',\n",
       " 'How would',\n",
       " 'How many',\n",
       " 'How Trump',\n",
       " 'How we',\n",
       " 'How Indian',\n",
       " \"How can't\",\n",
       " 'What do',\n",
       " 'What are',\n",
       " 'What is',\n",
       " 'What the',\n",
       " 'What it',\n",
       " 'What does',\n",
       " 'What you',\n",
       " 'What can',\n",
       " 'What did',\n",
       " 'What a',\n",
       " \"What don't\",\n",
       " 'What I',\n",
       " 'What will',\n",
       " 'What there',\n",
       " 'What would',\n",
       " 'What many',\n",
       " 'What Trump',\n",
       " 'What we',\n",
       " 'What Indian',\n",
       " \"What can't\",\n",
       " 'Do do',\n",
       " 'Do are',\n",
       " 'Do is',\n",
       " 'Do the',\n",
       " 'Do it',\n",
       " 'Do does',\n",
       " 'Do you',\n",
       " 'Do can',\n",
       " 'Do did',\n",
       " 'Do a',\n",
       " \"Do don't\",\n",
       " 'Do I',\n",
       " 'Do will',\n",
       " 'Do there',\n",
       " 'Do would',\n",
       " 'Do many',\n",
       " 'Do Trump',\n",
       " 'Do we',\n",
       " 'Do Indian',\n",
       " \"Do can't\",\n",
       " 'Are do',\n",
       " 'Are are',\n",
       " 'Are is',\n",
       " 'Are the',\n",
       " 'Are it',\n",
       " 'Are does',\n",
       " 'Are you',\n",
       " 'Are can',\n",
       " 'Are did',\n",
       " 'Are a',\n",
       " \"Are don't\",\n",
       " 'Are I',\n",
       " 'Are will',\n",
       " 'Are there',\n",
       " 'Are would',\n",
       " 'Are many',\n",
       " 'Are Trump',\n",
       " 'Are we',\n",
       " 'Are Indian',\n",
       " \"Are can't\",\n",
       " 'If do',\n",
       " 'If are',\n",
       " 'If is',\n",
       " 'If the',\n",
       " 'If it',\n",
       " 'If does',\n",
       " 'If you',\n",
       " 'If can',\n",
       " 'If did',\n",
       " 'If a',\n",
       " \"If don't\",\n",
       " 'If I',\n",
       " 'If will',\n",
       " 'If there',\n",
       " 'If would',\n",
       " 'If many',\n",
       " 'If Trump',\n",
       " 'If we',\n",
       " 'If Indian',\n",
       " \"If can't\",\n",
       " 'Can do',\n",
       " 'Can are',\n",
       " 'Can is',\n",
       " 'Can the',\n",
       " 'Can it',\n",
       " 'Can does',\n",
       " 'Can you',\n",
       " 'Can can',\n",
       " 'Can did',\n",
       " 'Can a',\n",
       " \"Can don't\",\n",
       " 'Can I',\n",
       " 'Can will',\n",
       " 'Can there',\n",
       " 'Can would',\n",
       " 'Can many',\n",
       " 'Can Trump',\n",
       " 'Can we',\n",
       " 'Can Indian',\n",
       " \"Can can't\",\n",
       " 'Should do',\n",
       " 'Should are',\n",
       " 'Should is',\n",
       " 'Should the',\n",
       " 'Should it',\n",
       " 'Should does',\n",
       " 'Should you',\n",
       " 'Should can',\n",
       " 'Should did',\n",
       " 'Should a',\n",
       " \"Should don't\",\n",
       " 'Should I',\n",
       " 'Should will',\n",
       " 'Should there',\n",
       " 'Should would',\n",
       " 'Should many',\n",
       " 'Should Trump',\n",
       " 'Should we',\n",
       " 'Should Indian',\n",
       " \"Should can't\",\n",
       " 'When do',\n",
       " 'When are',\n",
       " 'When is',\n",
       " 'When the',\n",
       " 'When it',\n",
       " 'When does',\n",
       " 'When you',\n",
       " 'When can',\n",
       " 'When did',\n",
       " 'When a',\n",
       " \"When don't\",\n",
       " 'When I',\n",
       " 'When will',\n",
       " 'When there',\n",
       " 'When would',\n",
       " 'When many',\n",
       " 'When Trump',\n",
       " 'When we',\n",
       " 'When Indian',\n",
       " \"When can't\",\n",
       " 'Does do',\n",
       " 'Does are',\n",
       " 'Does is',\n",
       " 'Does the',\n",
       " 'Does it',\n",
       " 'Does does',\n",
       " 'Does you',\n",
       " 'Does can',\n",
       " 'Does did',\n",
       " 'Does a',\n",
       " \"Does don't\",\n",
       " 'Does I',\n",
       " 'Does will',\n",
       " 'Does there',\n",
       " 'Does would',\n",
       " 'Does many',\n",
       " 'Does Trump',\n",
       " 'Does we',\n",
       " 'Does Indian',\n",
       " \"Does can't\",\n",
       " 'I do',\n",
       " 'I are',\n",
       " 'I is',\n",
       " 'I the',\n",
       " 'I it',\n",
       " 'I does',\n",
       " 'I you',\n",
       " 'I can',\n",
       " 'I did',\n",
       " 'I a',\n",
       " \"I don't\",\n",
       " 'I I',\n",
       " 'I will',\n",
       " 'I there',\n",
       " 'I would',\n",
       " 'I many',\n",
       " 'I Trump',\n",
       " 'I we',\n",
       " 'I Indian',\n",
       " \"I can't\",\n",
       " 'Did do',\n",
       " 'Did are',\n",
       " 'Did is',\n",
       " 'Did the',\n",
       " 'Did it',\n",
       " 'Did does',\n",
       " 'Did you',\n",
       " 'Did can',\n",
       " 'Did did',\n",
       " 'Did a',\n",
       " \"Did don't\",\n",
       " 'Did I',\n",
       " 'Did will',\n",
       " 'Did there',\n",
       " 'Did would',\n",
       " 'Did many',\n",
       " 'Did Trump',\n",
       " 'Did we',\n",
       " 'Did Indian',\n",
       " \"Did can't\",\n",
       " 'Will do',\n",
       " 'Will are',\n",
       " 'Will is',\n",
       " 'Will the',\n",
       " 'Will it',\n",
       " 'Will does',\n",
       " 'Will you',\n",
       " 'Will can',\n",
       " 'Will did',\n",
       " 'Will a',\n",
       " \"Will don't\",\n",
       " 'Will I',\n",
       " 'Will will',\n",
       " 'Will there',\n",
       " 'Will would',\n",
       " 'Will many',\n",
       " 'Will Trump',\n",
       " 'Will we',\n",
       " 'Will Indian',\n",
       " \"Will can't\",\n",
       " 'Would do',\n",
       " 'Would are',\n",
       " 'Would is',\n",
       " 'Would the',\n",
       " 'Would it',\n",
       " 'Would does',\n",
       " 'Would you',\n",
       " 'Would can',\n",
       " 'Would did',\n",
       " 'Would a',\n",
       " \"Would don't\",\n",
       " 'Would I',\n",
       " 'Would will',\n",
       " 'Would there',\n",
       " 'Would would',\n",
       " 'Would many',\n",
       " 'Would Trump',\n",
       " 'Would we',\n",
       " 'Would Indian',\n",
       " \"Would can't\",\n",
       " 'Who do',\n",
       " 'Who are',\n",
       " 'Who is',\n",
       " 'Who the',\n",
       " 'Who it',\n",
       " 'Who does',\n",
       " 'Who you',\n",
       " 'Who can',\n",
       " 'Who did',\n",
       " 'Who a',\n",
       " \"Who don't\",\n",
       " 'Who I',\n",
       " 'Who will',\n",
       " 'Who there',\n",
       " 'Who would',\n",
       " 'Who many',\n",
       " 'Who Trump',\n",
       " 'Who we',\n",
       " 'Who Indian',\n",
       " \"Who can't\",\n",
       " 'Was do',\n",
       " 'Was are',\n",
       " 'Was is',\n",
       " 'Was the',\n",
       " 'Was it',\n",
       " 'Was does',\n",
       " 'Was you',\n",
       " 'Was can',\n",
       " 'Was did',\n",
       " 'Was a',\n",
       " \"Was don't\",\n",
       " 'Was I',\n",
       " 'Was will',\n",
       " 'Was there',\n",
       " 'Was would',\n",
       " 'Was many',\n",
       " 'Was Trump',\n",
       " 'Was we',\n",
       " 'Was Indian',\n",
       " \"Was can't\",\n",
       " 'Which do',\n",
       " 'Which are',\n",
       " 'Which is',\n",
       " 'Which the',\n",
       " 'Which it',\n",
       " 'Which does',\n",
       " 'Which you',\n",
       " 'Which can',\n",
       " 'Which did',\n",
       " 'Which a',\n",
       " \"Which don't\",\n",
       " 'Which I',\n",
       " 'Which will',\n",
       " 'Which there',\n",
       " 'Which would',\n",
       " 'Which many',\n",
       " 'Which Trump',\n",
       " 'Which we',\n",
       " 'Which Indian',\n",
       " \"Which can't\",\n",
       " 'As do',\n",
       " 'As are',\n",
       " 'As is',\n",
       " 'As the',\n",
       " 'As it',\n",
       " 'As does',\n",
       " 'As you',\n",
       " 'As can',\n",
       " 'As did',\n",
       " 'As a',\n",
       " \"As don't\",\n",
       " 'As I',\n",
       " 'As will',\n",
       " 'As there',\n",
       " 'As would',\n",
       " 'As many',\n",
       " 'As Trump',\n",
       " 'As we',\n",
       " 'As Indian',\n",
       " \"As can't\",\n",
       " 'Have do',\n",
       " 'Have are',\n",
       " 'Have is',\n",
       " 'Have the',\n",
       " 'Have it',\n",
       " 'Have does',\n",
       " 'Have you',\n",
       " 'Have can',\n",
       " 'Have did',\n",
       " 'Have a',\n",
       " \"Have don't\",\n",
       " 'Have I',\n",
       " 'Have will',\n",
       " 'Have there',\n",
       " 'Have would',\n",
       " 'Have many',\n",
       " 'Have Trump',\n",
       " 'Have we',\n",
       " 'Have Indian',\n",
       " \"Have can't\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrueCountNGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ngrams(text):\n",
    "    n_grams = ngrams(word_tokenize(text), 2)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def countStartWordNGram_anywhereT(x):\n",
    "    zeros = np.zeros(len(TrueCountNGram))\n",
    "    for item in get_ngrams(x):\n",
    "        if item in TrueCountNGram:\n",
    "            zeros[TrueCountNGram.index(item)] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def countStartWordNGram_onlyBeginingT(x):\n",
    "    zeros = np.zeros(len(TrueCountNGram))\n",
    "    if len(get_ngrams(x))>0:\n",
    "        if get_ngrams(x)[0] in TrueCountNGram:\n",
    "            zeros[TrueCountNGram.index(get_ngrams(x)[0])] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "def countStartWordOccurenceNGramT(x):\n",
    "    count = 0\n",
    "    for item in get_ngrams(x):\n",
    "        if item in TrueCountNGram:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def countStartWordNGram_anywhereF(x):\n",
    "    zeros = np.zeros(len(FalseCountNGram))\n",
    "    for item in get_ngrams(x):\n",
    "        if item in FalseCountNGram:\n",
    "            zeros[FalseCountNGram.index(item)] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "\n",
    "def countStartWordNGram_onlyBeginingF(x):\n",
    "    zeros = np.zeros(len(FalseCountNGram))\n",
    "    if len(get_ngrams(x))>0:\n",
    "        if get_ngrams(x)[0] in FalseCountNGram:\n",
    "            zeros[FalseCountNGram.index(get_ngrams(x)[0])] = 1\n",
    "            return zeros\n",
    "    return zeros\n",
    "\n",
    "def countStartWordOccurenceNGramF(x):\n",
    "    count = 0\n",
    "    for item in get_ngrams(x):\n",
    "        if item in FalseCountNGram:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "# def get_ngrams(text):\n",
    "#     n_grams = ngrams(word_tokenize(text), 2)\n",
    "#     return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['count2gram_anywhere_inText'] = -1\n",
    "df1['count2gram_anywhere_inText'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWordNGram_anywhereT)\n",
    "df1['count2gram_anywhere_inText'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWordNGram_anywhereF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['count2gram_Occurence'] = -1\n",
    "df1['count2gram_Occurence'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWordOccurenceNGramT)\n",
    "df1['count2gram_Occurence'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWordOccurenceNGramF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9c9e84a88fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count2gram_onlyAtStart_inText'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count2gram_onlyAtStart_inText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3True\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountStartWordNGram_onlyBeginingT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count2gram_onlyAtStart_inText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3False\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountStartWordNGram_onlyBeginingF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-aa5f3a3e4c54>\u001b[0m in \u001b[0;36mcountStartWordNGram_onlyBeginingT\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcountStartWordNGram_onlyBeginingT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrueCountNGram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTrueCountNGram\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mzeros\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrueCountNGram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-aa5f3a3e4c54>\u001b[0m in \u001b[0;36mget_ngrams\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mn_grams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgrams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_grams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     return [token for sent in sentences\n\u001b[0m\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 130\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/nltk/tokenize/treebank.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df1['count2gram_onlyAtStart_inText'] = -1\n",
    "df1['count2gram_onlyAtStart_inText'].loc[df3['target'] == 1] = df3True['question_text'].apply(countStartWordNGram_onlyBeginingT)\n",
    "df1['count2gram_onlyAtStart_inText'].loc[df3['target'] == 0] = df3False['question_text'].apply(countStartWordNGram_onlyBeginingF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
